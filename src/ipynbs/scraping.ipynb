{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading packages\n",
    "\n",
    "# utils\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# scraping\n",
    "from urllib.request import urlopen, Request\n",
    "from urllib.error import HTTPError, URLError\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`airlinequality.com` had a blocker for the default `urllib` agent, so this workaround was found in order to correctly scrape the reviews.\n",
    "\n",
    "Source:\n",
    "https://stackoverflow.com/questions/16627227/http-error-403-in-python-3-web-scraping\n",
    "\n",
    "Enable some default error handling in case the site cannot be accessed, and tell us why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sneaky_request(url):\n",
    "    \"\"\"\n",
    "    sneaky_request is a function designed to get around some pages blocking web scraping.\n",
    "    It uses a different User-Agent than the default `python urllib/3.X.X`\n",
    "    \n",
    "    Args:\n",
    "        url (str) : url of the website desired to be scraped\n",
    "    \n",
    "    Return:\n",
    "        open_url (HTTPResponse) : the HTTP response of the input URL\n",
    "    \"\"\"\n",
    "    try:\n",
    "        req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        open_url = urlopen(req)\n",
    "    except HTTPError as error:\n",
    "        print(\"Error code: \", error.code)\n",
    "        print(\"The reason for the exception:\", error.reason)\n",
    "    \n",
    "    return open_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw_reviews_url = sneaky_request(\"https://www.airlinequality.com/airline-reviews/germanwings/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's double check to ensure that this has gone correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.airlinequality.com/airline-reviews/germanwings/\n",
      "Status: OK\n"
     ]
    }
   ],
   "source": [
    "print(gw_reviews_url.geturl())\n",
    "print(\"Status:\",gw_reviews_url.reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `BeautifulSoup` to explore and scrape the pages for the relevant info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw_reviews = BeautifulSoup(gw_reviews_url.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to traverse all of the pages in order to extract all of the reviews; this means opening each subsequent page and extracting each review.\n",
    "\n",
    "The following `while` loop iterates over each subsequent review page, terminating when there are no further pages to scrape.  The airline review information is stored in `reviews`, to be parsed after extracting all of the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the initial list and condition to keep scraping\n",
    "reviews = []\n",
    "keep_going = True\n",
    "\n",
    "while keep_going:\n",
    "    \n",
    "    # store the customer reviews in a list for later parsing\n",
    "    if len(reviews) == 0:\n",
    "        # if it is the first page, create the list\n",
    "        reviews = gw_reviews.find_all(\"article\", {\"itemprop\" : \"review\"})\n",
    "    else:\n",
    "        # concatenate the next pages reviews\n",
    "        for review in gw_reviews.find_all(\"article\", {\"itemprop\" : \"review\"}):\n",
    "            reviews.append(review)\n",
    "    \n",
    "    # find the next page tag, use it to construct the next page to access\n",
    "    # if it is the last page, end the loop\n",
    "    try:\n",
    "        next_page = gw_reviews.find(\"a\", string = \">>\")[\"href\"]\n",
    "        next_page_url = \"https://www.airlinequality.com\" + next_page\n",
    "    except: \n",
    "        keep_going = False\n",
    "        \n",
    "    # open the next page, but wait 5 seconds to be polite \n",
    "    # and not overload the server\n",
    "    time.sleep(5)\n",
    "    gw_reviews_url = sneaky_request(next_page_url)\n",
    "    gw_reviews = BeautifulSoup(gw_reviews_url.read())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the reviews are all extracted, construct a `pandas` dataframe with desired information.\n",
    "\n",
    "First, double check that all `146` reviews are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate through the reviews, building lists of the required information.\n",
    "\n",
    "Note that this could be done in parallel using a library such as [`joblib`](https://joblib.readthedocs.io/en/latest/), but the dataset is so small that there is no need to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some functions to help us later\n",
    "\n",
    "def safe_extract(extracted_tag, replacement_value = None):\n",
    "    \"\"\"\n",
    "    safe_extract is used to extract text from html tags when sometimes the tag doesn't exist.\n",
    "    Instead of throwing an error, it provides a defined replacement value\n",
    "    \n",
    "    Args:\n",
    "        extracted_tag (Tag) : BeautifulSoup html tag containing the desired text\n",
    "        replacement_value (int, bool, str, dbl...) : if the tag doesn't exist, what\n",
    "                                                     should it be replaced with?\n",
    "                                                     \n",
    "    Return:\n",
    "        the extracted text if it exists, if not then the replacement value\n",
    "    \"\"\"\n",
    "    try:\n",
    "        value = extracted_tag.text\n",
    "    except:\n",
    "        value = replacement_value\n",
    "        \n",
    "    return value\n",
    "\n",
    "def sibling_extract(extracted_tag, next_tag = \"td\", replacement_value = None):\n",
    "    \"\"\"\n",
    "    sibling_extract is used to extract text from a html tag's sibling when sometimes the tag doesn't exist.\n",
    "    Instead of throwing an error, it provides a defined replacement value\n",
    "    \n",
    "    Args:\n",
    "        extracted_tag (Tag) : BeautifulSoup html tag containing the desired text\n",
    "        next_tag (str) : next tag type to find\n",
    "        replacement_value (int, bool, str, dbl...) : if the tag doesn't exist, what\n",
    "                                                     should it be replaced with?\n",
    "                                                     \n",
    "    Return:\n",
    "        the extracted text if it exists, if not then the replacement value\n",
    "    \"\"\"\n",
    "    try: \n",
    "        # using find_next to find the sibling with the specified tag\n",
    "        value = extracted_tag.find_next(next_tag).text\n",
    "    except:\n",
    "        value = None\n",
    "    \n",
    "    return value\n",
    "\n",
    "def star_extract(extracted_tag, next_tag = \"td\", replacement_value = None):\n",
    "    \"\"\"\n",
    "    star_extract is used to extract the number of rated stars from a html tag.\n",
    "    When the rating doesn't exist, instead of throwing an error \n",
    "    it provides a defined replacement value\n",
    "    \n",
    "    Args:\n",
    "        extracted_tag (Tag) : BeautifulSoup html tag containing the desired star ratings\n",
    "        next_tag (str) : next tag type to find\n",
    "        replacement_value (int, bool, str, dbl...) : if the tag doesn't exist, what\n",
    "                                                     should it be replaced with?\n",
    "                                                     \n",
    "    Return:\n",
    "        the extracted number of stars if it exists, if not then the replacement value\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # find the number of stars that have class = \"star fill\" representing\n",
    "        # the number of rated stars.\n",
    "        #\n",
    "        # For example, a 4 star rating will have 4 class = \"star fill\" and\n",
    "        # one class = \"star\"\n",
    "        #\n",
    "        # the sibling tag will need to be found as well since\n",
    "        # the class value is not unique for the number of stars\n",
    "        filled_star_tags = extracted_tag.find_next(next_tag).find_all(\"span\", {\"class\" : \"star fill\"})\n",
    "        \n",
    "        # the number of filled in star tags is the rating\n",
    "        value = len(filled_star_tags)\n",
    "        \n",
    "    except:\n",
    "        value = None\n",
    "        \n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**\n",
    "\n",
    "I used the functions above but in retrospect, should have instead used a single function with a format of:\n",
    "\n",
    "```\n",
    "try:\n",
    "    append tag query\n",
    "except:\n",
    "    append None\n",
    "```\n",
    "\n",
    "But in interest of time I kept moving forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a dictionary structure for easily working with\n",
    "parsed_reviews = {\n",
    "    \"title\" : [],\n",
    "    \"review_value\" : [],\n",
    "    \"n_user_reviews\" : [],\n",
    "    \"reviewer_name\" : [],\n",
    "    \"reviewer_country\" : [],\n",
    "    \"date_of_review\" : [],\n",
    "    \"review_text\" : [],\n",
    "    \"aircraft\" :[],\n",
    "    \"traveller_type\" : [],\n",
    "    \"seat_type\" : [],\n",
    "    \"route\" : [],\n",
    "    \"date_flown\" : [],\n",
    "    \"seat_comfort_rating\" : [],\n",
    "    \"cabin_staff_service_rating\" : [],\n",
    "    \"food_and_beverages_rating\" : [],\n",
    "    \"inflight_entertainment_rating\" : [],\n",
    "    \"ground_service_rating\" : [],\n",
    "    \"value_for_money_rating\" : [],\n",
    "    \"recommendation\" : []\n",
    "}\n",
    "\n",
    "\n",
    "# iterate through all reviews, extracting information from each\n",
    "# and storing in the parsed_reviews dict\n",
    "for review in reviews:\n",
    "\n",
    "    # extract review title\n",
    "    review_title = review.find(\"h2\", {\"class\" : \"text_header\"})\n",
    "    parsed_reviews[\"title\"].append(safe_extract(review_title))\n",
    "\n",
    "    # extract review value out of 10\n",
    "    review_value = review.find(\"span\", {\"itemprop\" : \"ratingValue\"})\n",
    "    \n",
    "    # if there is no value out of 10, enter None instead using `safe_extract`\n",
    "    parsed_reviews[\"review_value\"].append(safe_extract(review_value))\n",
    "\n",
    "    # extract number of reviews by the reviewer\n",
    "    n_reviews = review.find(\"span\", {\"class\" : \"userStatusReviewCount\"})\n",
    "    parsed_reviews[\"n_user_reviews\"].append(safe_extract(n_reviews))\n",
    "    \n",
    "    # extract the reviewer\n",
    "    reviewer_name = review.find(\"span\", {\"itemprop\" : \"name\"})\n",
    "    parsed_reviews[\"reviewer_name\"].append(safe_extract(reviewer_name))\n",
    "\n",
    "    # extract the country of the reviewer\n",
    "    reviewer_country = review.find(\"h3\", {\"class\" : \"text_sub_header userStatusWrapper\"})\n",
    "    parsed_reviews[\"reviewer_country\"].append(safe_extract(reviewer_country))\n",
    "    \n",
    "    # extract the date of the review\n",
    "    date_of_review = review.find(\"time\", {\"itemprop\" : \"datePublished\"})\n",
    "    parsed_reviews[\"date_of_review\"].append(safe_extract(date_of_review))\n",
    "    \n",
    "    # extract the review text\n",
    "    review_text = review.find(\"div\", {\"class\" : \"text_content\"})\n",
    "    parsed_reviews[\"review_text\"].append(safe_extract(review_text))\n",
    "    \n",
    "    # extract the aircraft\n",
    "    # there are multiple td with class = \"review-value\"\n",
    "    # so we need to find the sibling header for aircraft then find it's sibling \n",
    "    # in order to find the aircraft type.  Use sibling_extract for this\n",
    "    aircraft = review.find(\"td\", {\"class\" : \"review-rating-header aircraft\"})\n",
    "    aircraft_value = sibling_extract(aircraft)\n",
    "    parsed_reviews[\"aircraft\"].append(aircraft_value)\n",
    "    \n",
    "    # extract the type of traveller\n",
    "    traveller_type = review.find(\"td\", {\"class\" : \"review-rating-header type_of_traveller\"})\n",
    "    traveller_type_value = sibling_extract(traveller_type)\n",
    "    parsed_reviews[\"traveller_type\"].append(traveller_type_value)\n",
    "    \n",
    "    # extract seat type\n",
    "    seat_type = review.find(\"td\", {\"class\" : \"review-rating-header cabin_flown\"})\n",
    "    seat_type_value = sibling_extract(seat_type)\n",
    "    parsed_reviews[\"seat_type\"].append(seat_type_value)\n",
    "    \n",
    "    # extract the route\n",
    "    route = review.find(\"td\", {\"class\" : \"review-rating-header route\"})\n",
    "    route_value = sibling_extract(route)\n",
    "    parsed_reviews[\"route\"].append(route_value) \n",
    "\n",
    "    # extract the date flown\n",
    "    date_flown = review.find(\"td\", {\"class\" : \"review-rating-header date_flown\"})\n",
    "    date_flown_value = sibling_extract(date_flown)\n",
    "    parsed_reviews[\"date_flown\"].append(date_flown_value) \n",
    "\n",
    "    # extract the seat comfort rating out of 5\n",
    "    # need to find the sibling in order to narrow down the number of stars for \n",
    "    # seat comfort or other ratings\n",
    "    seat_comfort_rating = review.find(\"td\", {\"class\" : \"review-rating-header seat_comfort\"})\n",
    "    parsed_reviews[\"seat_comfort_rating\"].append(star_extract(seat_comfort_rating))\n",
    "    \n",
    "    # extract the cabin staff service rating out of 5\n",
    "    cabin_staff_service_rating = review.find(\"td\", {\"class\" : \"review-rating-header cabin_staff_service\"})\n",
    "    parsed_reviews[\"cabin_staff_service_rating\"].append(star_extract(cabin_staff_service_rating))\n",
    "\n",
    "    # extract the food and beverages rating out of 5\n",
    "    food_and_beverages_rating = review.find(\"td\", {\"class\" : \"review-rating-header food_and_beverages\"})\n",
    "    parsed_reviews[\"food_and_beverages_rating\"].append(star_extract(food_and_beverages_rating))\n",
    "    \n",
    "    # extract the inflight entertainment rating out of 5\n",
    "    inflight_entertainment_rating = review.find(\"td\", {\"class\" : \"review-rating-header inflight_entertainment\"})\n",
    "    parsed_reviews[\"inflight_entertainment_rating\"].append(star_extract(inflight_entertainment_rating))\n",
    "    \n",
    "    # extract the ground service rating out of 5\n",
    "    ground_service_rating = review.find(\"td\", {\"class\" : \"review-rating-header ground_service\"})\n",
    "    parsed_reviews[\"ground_service_rating\"].append(star_extract(ground_service_rating))\n",
    "\n",
    "    # extract the value for money rating out of 5\n",
    "    value_for_money_rating = review.find(\"td\", {\"class\" : \"review-rating-header value_for_money\"})\n",
    "    parsed_reviews[\"value_for_money_rating\"].append(star_extract(value_for_money_rating))\n",
    "\n",
    "    # extract if the review recommended Germanwings or not\n",
    "    recommendation = review.find(\"td\", {\"class\" : \"review-rating-header recommended\"}).find_next(\"td\")\n",
    "    parsed_reviews[\"recommendation\"].append(recommendation.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all information is parsed, convert to a `pandas` dataframe and save as a `csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_reviews_df = pd.DataFrame(parsed_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>review_value</th>\n",
       "      <th>n_user_reviews</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>reviewer_country</th>\n",
       "      <th>date_of_review</th>\n",
       "      <th>review_text</th>\n",
       "      <th>aircraft</th>\n",
       "      <th>traveller_type</th>\n",
       "      <th>seat_type</th>\n",
       "      <th>route</th>\n",
       "      <th>date_flown</th>\n",
       "      <th>seat_comfort_rating</th>\n",
       "      <th>cabin_staff_service_rating</th>\n",
       "      <th>food_and_beverages_rating</th>\n",
       "      <th>inflight_entertainment_rating</th>\n",
       "      <th>ground_service_rating</th>\n",
       "      <th>value_for_money_rating</th>\n",
       "      <th>recommendation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Seat was fine with enough legroom\"</td>\n",
       "      <td>7</td>\n",
       "      <td>8 reviews</td>\n",
       "      <td>Sander van Kan</td>\n",
       "      <td>\\n\\n8 reviews\\n\\n\\n\\nSander van Kan (Netherlan...</td>\n",
       "      <td>1st July 2019</td>\n",
       "      <td>✅ Trip Verified | Dusseldorf to Berlin. Eurowi...</td>\n",
       "      <td>A319</td>\n",
       "      <td>Couple Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Dusseldorf to Berlin</td>\n",
       "      <td>June 2019</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"crew were smiling and good\"</td>\n",
       "      <td>6</td>\n",
       "      <td>8 reviews</td>\n",
       "      <td>Sander van Kan</td>\n",
       "      <td>\\n\\n8 reviews\\n\\n\\n\\nSander van Kan (Netherlan...</td>\n",
       "      <td>1st July 2019</td>\n",
       "      <td>✅ Trip Verified | Berlin to Dusseldorf. Eurowi...</td>\n",
       "      <td>A319</td>\n",
       "      <td>Couple Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>Berlin to Dusseldorf</td>\n",
       "      <td>June 2019</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"only two agents available\"</td>\n",
       "      <td>1</td>\n",
       "      <td>6 reviews</td>\n",
       "      <td>Andrew Maynard</td>\n",
       "      <td>\\n\\n6 reviews\\n\\n\\n\\nAndrew Maynard  (United K...</td>\n",
       "      <td>4th January 2017</td>\n",
       "      <td>Check in process at Cologne very poor. Flight ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Couple Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>CGN to MAN</td>\n",
       "      <td>January 2017</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"good flight and friendly staff\"</td>\n",
       "      <td>7</td>\n",
       "      <td>1 reviews</td>\n",
       "      <td>T Steen</td>\n",
       "      <td>\\n\\n1 reviews\\n\\n\\n\\nT Steen (Netherlands) 13t...</td>\n",
       "      <td>13th September 2016</td>\n",
       "      <td>✅ Verified Review |  Amsterdam to Stuttgart. G...</td>\n",
       "      <td>None</td>\n",
       "      <td>Business</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>AMS to STR</td>\n",
       "      <td>September 2016</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"never been treated as badly\"</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>Karen Kirner</td>\n",
       "      <td>\\n\\nKaren Kirner (Austria) 16th August 2016</td>\n",
       "      <td>16th August 2016</td>\n",
       "      <td>✅ Verified Review |  I have been a frequent tr...</td>\n",
       "      <td>None</td>\n",
       "      <td>Business</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>DUS to VIE</td>\n",
       "      <td>August 2016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 title review_value n_user_reviews  \\\n",
       "0  \"Seat was fine with enough legroom\"            7      8 reviews   \n",
       "1         \"crew were smiling and good\"            6      8 reviews   \n",
       "2          \"only two agents available\"            1      6 reviews   \n",
       "3     \"good flight and friendly staff\"            7      1 reviews   \n",
       "4        \"never been treated as badly\"            1           None   \n",
       "\n",
       "     reviewer_name                                   reviewer_country  \\\n",
       "0   Sander van Kan  \\n\\n8 reviews\\n\\n\\n\\nSander van Kan (Netherlan...   \n",
       "1   Sander van Kan  \\n\\n8 reviews\\n\\n\\n\\nSander van Kan (Netherlan...   \n",
       "2  Andrew Maynard   \\n\\n6 reviews\\n\\n\\n\\nAndrew Maynard  (United K...   \n",
       "3          T Steen  \\n\\n1 reviews\\n\\n\\n\\nT Steen (Netherlands) 13t...   \n",
       "4     Karen Kirner        \\n\\nKaren Kirner (Austria) 16th August 2016   \n",
       "\n",
       "        date_of_review                                        review_text  \\\n",
       "0        1st July 2019  ✅ Trip Verified | Dusseldorf to Berlin. Eurowi...   \n",
       "1        1st July 2019  ✅ Trip Verified | Berlin to Dusseldorf. Eurowi...   \n",
       "2     4th January 2017  Check in process at Cologne very poor. Flight ...   \n",
       "3  13th September 2016  ✅ Verified Review |  Amsterdam to Stuttgart. G...   \n",
       "4     16th August 2016  ✅ Verified Review |  I have been a frequent tr...   \n",
       "\n",
       "  aircraft  traveller_type      seat_type                 route  \\\n",
       "0     A319  Couple Leisure  Economy Class  Dusseldorf to Berlin   \n",
       "1     A319  Couple Leisure  Economy Class  Berlin to Dusseldorf   \n",
       "2     None  Couple Leisure  Economy Class            CGN to MAN   \n",
       "3     None        Business  Economy Class            AMS to STR   \n",
       "4     None        Business  Economy Class            DUS to VIE   \n",
       "\n",
       "       date_flown  seat_comfort_rating  cabin_staff_service_rating  \\\n",
       "0       June 2019                  4.0                         3.0   \n",
       "1       June 2019                  3.0                         3.0   \n",
       "2    January 2017                  2.0                         2.0   \n",
       "3  September 2016                  5.0                         5.0   \n",
       "4     August 2016                  1.0                         1.0   \n",
       "\n",
       "   food_and_beverages_rating  inflight_entertainment_rating  \\\n",
       "0                        NaN                            1.0   \n",
       "1                        NaN                            1.0   \n",
       "2                        NaN                            NaN   \n",
       "3                        1.0                            NaN   \n",
       "4                        NaN                            NaN   \n",
       "\n",
       "   ground_service_rating  value_for_money_rating recommendation  \n",
       "0                    3.0                     5.0            yes  \n",
       "1                    3.0                     5.0            yes  \n",
       "2                    1.0                     2.0             no  \n",
       "3                    5.0                     5.0            yes  \n",
       "4                    3.0                     1.0             no  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_reviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There remains some cleanup to do, but we will save this intermediate dataset and clean it in the next notebook/script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
