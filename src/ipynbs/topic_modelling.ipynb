{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling\n",
    "\n",
    "#### Evan Yathon\n",
    "\n",
    "This notebook is intended to be run with papermill from the project root.\n",
    "\n",
    "The purpose of this notebook is to process the review title and content to extract key phrases in each review.  Then key phrases will be used in a regression analysis to find out what is most important for a reviewer in recommending or not recommending the airline.\n",
    "\n",
    "Topic modelling using LDA will be the tool of choice.\n",
    "\n",
    "Usage:\n",
    "\n",
    "`papermill src/ipynbs/topic_modelling.ipynb -p load_path data/cleaned_gw_reviews.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#parameters section for Papermill\n",
    "\n",
    "load_path = \"../../data/cleaned_gw_reviews.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading packages\n",
    "\n",
    "# utils\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# NLP\n",
    "import spacy\n",
    "import gensim \n",
    "import gensim.corpora as corpora\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim import models\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "# display preference for ipynbs\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure the dates are parsed correctly with parse_dates argument\n",
    "reviews = pd.read_csv(load_path, parse_dates = [\"date_of_review\", \"date_flown\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modelling - Preprocessing\n",
    "\n",
    "Prior to LDA, preprocessing of the text is necessary.  We need to:\n",
    "- Tokenize each document (review)\n",
    "- Minimum token length\n",
    "- Remove stopwords\n",
    "- Lemmatize\n",
    "- Consider only specific parts of speech (nouns, verbs etc.)\n",
    "\n",
    "Use [`spaCy`](https://spacy.io/) for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the english spacy model\n",
    "eng_nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to preprocess the reviews and review titles\n",
    "\n",
    "def preprocess_text(text, min_token_len = 2, relevant_pos = [\"NOUN\", \"VERB\", \"ADJ\"]):\n",
    "    \"\"\"\n",
    "    Given text, min_token_len, and relevant_pos carry out preprocessing of the text \n",
    "    and return a preprocessed string. \n",
    "    \n",
    "    Keyword arguments:\n",
    "    text (str): the text to be preprocessed\n",
    "    min_token_len (int): min_token_length required\n",
    "    relevant_pos (list): a list of relevant pos tags\n",
    "    \n",
    "    Returns: (str) the preprocessed text\n",
    "    \"\"\"\n",
    "    # use several regex expressions to preprocess strange characters\n",
    "    # or unwanted text\n",
    "    \n",
    "    # remove verified emoji\n",
    "    text = re.sub(r\"âœ…\", \"\", text)\n",
    "    \n",
    "    # remove verified review and trip verified\n",
    "    text = re.sub(r\"Verified Review|Trip Verified\", \"\", text)\n",
    "    \n",
    "    # remove anything that is not a word\n",
    "    text = re.sub(r\"[^\\w]\", \" \", text)\n",
    "    \n",
    "    # replace multiple spaces with a single space\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    \n",
    "    # remove numbers\n",
    "    text = re.sub(r\"[0-9]+\", \"\", text)\n",
    "    \n",
    "    # change all text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # remove common terms found in topic modelling output\n",
    "    # eg/ germanwings, flight\n",
    "    # these words are not useful for this application as they\n",
    "    # are common terms found in most reviews, and won't be indicative of \n",
    "    # things that influenced their recommendation\n",
    "    terms = [\"flight\", \"germanwing\", \"fly\", \"review\"]\n",
    "    text = re.sub(\"|\".join(terms),\" \", text)\n",
    "    \n",
    "    # utilize spaCy to tokenize and break text into lemmas/POS:\n",
    "    # - remove stopwords\n",
    "    # - reduce words to their lemmas\n",
    "    # - only keep relevant parts of speech\n",
    "    # - remove short words less than min_token_len\n",
    "    \n",
    "    # spacy will utilize\n",
    "    doc = eng_nlp(text)\n",
    "    \n",
    "    processed_text = \"\"\n",
    "    \n",
    "    for token in doc:\n",
    "        if not token.is_stop and len(token.text) >= min_token_len and token.pos_ in relevant_pos:\n",
    "            processed_text += \" \" + token.lemma_\n",
    "    \n",
    "    return processed_text\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the preprocessing function to process all review texts and review titles.\n",
    "\n",
    "A good check will be to see if the review topics somewhat make sense with the title topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"clean_review_text\"] = reviews[\"review_text\"].apply(preprocess_text, min_token_len = 3)\n",
    "reviews[\"clean_title\"] = reviews[\"title\"].apply(preprocess_text, min_token_len = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reviews[[\"clean_review_text\", \"review_text\", \"clean_title\", \"title\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks mostly good, but I noticed that in the first review it is removing 'enough'.  This could be valuable in context, but I'll keep digging for now.  It's an issue since 'enough' is a stopword and is being removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modelling: Dictionary and Document-Term Co-occurrence Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the cleaned reviews and cleaned titles to \n",
    "# an array, required by corpora.Dictionary\n",
    "review_corpus = [doc.split() for doc in reviews[\"clean_review_text\"].tolist()]\n",
    "title_corpus = [doc.split() for doc in reviews[\"clean_title\"].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use gensim dictionary to map between words and integer ids\n",
    "dct_review = corpora.Dictionary(review_corpus)\n",
    "dct_title = corpora.Dictionary(title_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the document-term co-occurrence matrices\n",
    "doc_term_mat_review = [dct_review.doc2bow(doc) for doc in review_corpus]\n",
    "doc_term_mat_title = [dct_title.doc2bow(doc) for doc in title_corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modelling:  LDA Topic Model\n",
    "\n",
    "Number of topics was tuned using the visualizations below by examining the Intertopic distance map.  When there was no overlap and the topics were separated by a fair amount, the number of topics was chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the LDA models\n",
    "# use a lower alpha, meaning that each document is representative of only a few topics\n",
    "# do this so that each review doesn't contain similar topics and will have variation\n",
    "# that we can use to figure out why the recommendation was a yes or no\n",
    "\n",
    "lda_review = models.LdaModel(corpus = doc_term_mat_review, id2word = dct_review, num_topics = 4, alpha = 0.5, passes = 5)\n",
    "lda_title = models.LdaModel(corpus = doc_term_mat_title, id2word = dct_title, num_topics = 3, alpha = 0.01, passes = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the topics and the words that describe them\n",
    "lda_review.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the topics and the words that describe them\n",
    "lda_title.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modelling: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the reviews \n",
    "pyLDAvis.enable_notebook()\n",
    "vis_reviews = pyLDAvis.gensim.prepare(lda_review, doc_term_mat_review, dct_review, sort_topics=False)\n",
    "vis_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the titles\n",
    "vis_titles = pyLDAvis.gensim.prepare(lda_title, doc_term_mat_title, dct_title, sort_topics=False)\n",
    "vis_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modelling: Assigning each Review a Topic\n",
    "\n",
    "Create a handy function to help assign topics to the reviews dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_correct_topics(lda_doc_topics):\n",
    "    \"\"\"\n",
    "    get_correct_topics uses an output LDA object to correctly place\n",
    "    LDA outputs to their correct topic column number for use in a\n",
    "    pandas dataframe\n",
    "    \n",
    "    Args:\n",
    "        lda_doc_topics (TransformedCorpus): Document topic probabilities obtained through\n",
    "                                            the .get_document_topics method of an LDA obj\n",
    "    Returns:\n",
    "        pandas dataframe of correctly assigned LDA topics\n",
    "    \"\"\"\n",
    "    # placeholder array with same number of rows as the input \n",
    "    # corpus and number of topics for columns\n",
    "    # initialize all zeros so that topics with missing probabilities\n",
    "    # will be zero\n",
    "    \n",
    "    topic_prob_array = np.zeros(pd.DataFrame(lda_doc_topics).shape)\n",
    "\n",
    "    for row_num, row in enumerate(lda_doc_topics):\n",
    "\n",
    "        # assign each topic to the correct\n",
    "        # topic[0] is the topic number\n",
    "        # topic[1] is the corresponding probability\n",
    "        for topic in row:\n",
    "            topic_prob_array[row_num, topic[0]] = topic[1]\n",
    "\n",
    "    topic_prob_df = pd.DataFrame(topic_prob_array)\n",
    "    \n",
    "    return topic_prob_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get both title and reviews dataframes, concatenate with `reviews`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_prob_df = get_correct_topics(lda_review.get_document_topics(doc_term_mat_review))\n",
    "title_prob_df = get_correct_topics(lda_title.get_document_topics(doc_term_mat_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_prob_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
